{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchDLMNIST",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnuragQ/python_apps/blob/master/PytorchDLMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tWvJlONYu0x2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kpezbr4P8N_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        n_layers=[]\n",
        "        \n",
        "        for i in range(len(layers)-2):\n",
        "            n_layers.append(nn.Linear(layers[i], layers[i+1]))\n",
        "            n_layers.append(nn.ReLU(inplace=True))\n",
        "        \n",
        "        n_layers.append(nn.Linear(layers[-2], layers[-1]))\n",
        "        \n",
        "        self.model = nn.ModuleList(n_layers)\n",
        "#         self.model= nn.Sequential(\n",
        "#             nn.Linear(784, 1000),\n",
        "#             nn.Linear(1000, 10)\n",
        "#         )\n",
        "    def forward(self, x):\n",
        "        x=x.view(-1,784)\n",
        "        for l in self.model:\n",
        "            x=l(x)\n",
        "        return x\n",
        "#     def set_masks(self, masks,layers):\n",
        "#         # Should be a less manual way to set masks\n",
        "#         # Leave it for the future\n",
        "#         for i in range(len(layers)-2):\n",
        "            \n",
        "#             self.n_layers[i].set_mask(masks[i])\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AWBu0YSv96OL",
        "colab_type": "code",
        "outputId": "ec79fb72-1b13-46b6-8945-fb659b951d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net = Net([784, 1000, 1000, 500, 200, 10]).to(device)\n",
        "optimizer = optim.RMSprop(net.parameters(), lr=1e-3)\n",
        "\n",
        "critic = nn.CrossEntropyLoss()\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (model): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=1000, bias=True)\n",
              "    (1): ReLU(inplace)\n",
              "    (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "    (3): ReLU(inplace)\n",
              "    (4): Linear(in_features=1000, out_features=500, bias=True)\n",
              "    (5): ReLU(inplace)\n",
              "    (6): Linear(in_features=500, out_features=200, bias=True)\n",
              "    (7): ReLU(inplace)\n",
              "    (8): Linear(in_features=200, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "QptKXKcY-HDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    datasets.MNIST('.', train=True, download=True, transform=train_transforms), batch_size=64, shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    datasets.MNIST('.', train=False, download=True, transform=test_transforms), batch_size=64, shuffle=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vx0_n4kOAnH2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epochs, model, optimizer, critic, train_dl):\n",
        "    model.train()\n",
        "    \n",
        "    for ep in range(epochs):\n",
        "        print(f'Epoch: {ep+1}')\n",
        "        for batch_i, (x_batch, y_batch) in enumerate(train_dl):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            preds = model(x_batch)\n",
        "            loss = critic(preds, y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if batch_i % 100 == 0:\n",
        "                pred_labels = torch.argmax(preds, dim=1)\n",
        "                acc = (pred_labels == y_batch).sum().float()\n",
        "                print(f'\\tLoss: {loss.item():.4f} \\t Accuracy: {acc/x_batch.shape[0]:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IA5RpDNdDYgq",
        "colab_type": "code",
        "outputId": "12195d78-a388-4b86-bee8-4ef6546d042d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "cell_type": "code",
      "source": [
        "train(2,net, optimizer, critic, train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "\tLoss: 2.3002 \t Accuracy: 0.11\n",
            "\tLoss: 0.5648 \t Accuracy: 0.91\n",
            "\tLoss: 0.1975 \t Accuracy: 0.92\n",
            "\tLoss: 0.1967 \t Accuracy: 0.94\n",
            "\tLoss: 0.1762 \t Accuracy: 0.95\n",
            "\tLoss: 0.1260 \t Accuracy: 0.97\n",
            "\tLoss: 0.1769 \t Accuracy: 0.95\n",
            "\tLoss: 0.0994 \t Accuracy: 0.95\n",
            "\tLoss: 0.0882 \t Accuracy: 0.97\n",
            "\tLoss: 0.1000 \t Accuracy: 0.97\n",
            "Epoch: 2\n",
            "\tLoss: 0.1601 \t Accuracy: 0.97\n",
            "\tLoss: 0.1944 \t Accuracy: 0.92\n",
            "\tLoss: 0.1700 \t Accuracy: 0.94\n",
            "\tLoss: 0.1246 \t Accuracy: 0.97\n",
            "\tLoss: 0.0297 \t Accuracy: 1.00\n",
            "\tLoss: 0.1931 \t Accuracy: 0.95\n",
            "\tLoss: 0.1375 \t Accuracy: 0.97\n",
            "\tLoss: 0.0616 \t Accuracy: 0.97\n",
            "\tLoss: 0.1417 \t Accuracy: 0.97\n",
            "\tLoss: 0.1367 \t Accuracy: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YE726OR9iU4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def weight_prune(model, pruning_perc):\n",
        "#     '''\n",
        "#     Prune pruning_perc% weights globally (not layer-wise)\n",
        "#     arXiv: 1606.09274\n",
        "#     '''    \n",
        "#     all_weights = []\n",
        "#     for p in model.parameters():\n",
        "#         if len(p.data.size()) != 1:\n",
        "#             all_weights += list(p.cpu().data.abs().numpy().flatten())\n",
        "#     threshold = np.percentile(np.array(all_weights), pruning_perc)\n",
        "\n",
        "#     # generate mask\n",
        "#     masks = []\n",
        "#     for p in model.parameters():\n",
        "#         if len(p.data.size()) != 1:\n",
        "#             pruned_inds = p.data.abs() > threshold\n",
        "#             masks.append(pruned_inds.float())\n",
        "#     return masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GN60tabyihm9",
        "colab_type": "code",
        "outputId": "a5fc64ad-9dd4-4ed6-cee7-68f7b6c8dab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test(model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            outputs = model(images.to(device))\n",
        "            outputs.data=outputs.data.to(device)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on test images: %d %%' % (\n",
        "        100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on test images: 97 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TCgX8PFrCUl6",
        "colab_type": "code",
        "outputId": "22224bbc-9358-47fa-956c-a2bc09269c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# print(threshold)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.05216322652995588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sbIXpz3EhUpz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weight_prune(model,percentage)\n",
        "    all_weights = []\n",
        "    for p in model.parameters():\n",
        "        if len(p.data.size()) != 1:\n",
        "            all_weights += list(p.cpu().data.abs().numpy().flatten())\n",
        "    threshold = np.percentile(np.array(all_weights), percentage)\n",
        "\n",
        "    for arr in model.model[0:6:2]:\n",
        "        for arr in model.model[0:7:2]:\n",
        "            arr.weight.data[abs(arr.weight.data)<threshold]=0.             \n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rugtvtkehYzH",
        "colab_type": "code",
        "outputId": "c7a3dde4-5cc5-4540-c33e-aa0cf79fe0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "net.model[2].weight.data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.1154,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0621,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0904,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0756,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "48vvu5QlhC3m",
        "colab_type": "code",
        "outputId": "50e9b89d-fa1b-4492-e735-3da4cdcaecb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test(net)\n",
        "weightPrune()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on test images: 96 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cqVK8SWMaR8Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cx5TWdWbaR_h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}